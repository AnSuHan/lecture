{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install -Uq python-dotenv langchain_teddynote langchain_openai langchain langchain-community faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv(\"./.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain/LangSmith API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì°¸ê³ : https://wikidocs.net/250954\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"Runnable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchainì—ì„œ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ë°©ë²•\n",
    "1. RunnablePassthrough\n",
    "2. RunnableParallel\n",
    "3. RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. `RunnablePassthrough`: ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ë„˜ê²¨(í†µê³¼ì‹œì¼œ)ì£¼ëŠ” ì—­í• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['word'], input_types={}, partial_variables={}, template='{word}ë¥¼ ì˜ì–´ë¡œ?')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001FCEB3598E0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001FC85D2F590>, root_client=<openai.OpenAI object at 0x000001FCEB358830>, root_async_client=<openai.AsyncOpenAI object at 0x000001FCEB3591F0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# prompt ì™€ llm ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = PromptTemplate.from_template(\"{word}ë¥¼ ì˜ì–´ë¡œ?\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = prompt | llm\n",
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chain ì„ `invoke()` í•˜ì—¬ ì‹¤í–‰í•  ë•ŒëŠ” ì…ë ¥ ë°ì´í„°ì˜ íƒ€ì…ì€ ***ë”•ì…”ë„ˆë¦¬***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='apple', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 15, 'total_tokens': 16, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CJsa21wGZwlaRI9UmSizK0JziHhNX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bd87b7ea-660c-41ef-872b-224841af288e-0', usage_metadata={'input_tokens': 15, 'output_tokens': 1, 'total_tokens': 16, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "chain.invoke({\"word\": 'ì‚¬ê³¼'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, 1ê°œì˜ ë³€ìˆ˜ë§Œ í…œí”Œë¦¿ì— í¬í•¨í•˜ê³  ìˆë‹¤ë©´, ê°’ë§Œ ì „ë‹¬í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='apple', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 15, 'total_tokens': 16, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CJsa5DIaZOhM11vVupxYLf9JroWn5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8692d208-eacf-42dc-b929-f846fe28c6a6-0', usage_metadata={'input_tokens': 15, 'output_tokens': 1, 'total_tokens': 16, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "chain.invoke('ì‚¬ê³¼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Artificial Intelligence (AI)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 17, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CJsbe4arT6MEI6LJDodsGM2jbj9gc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e3a399ff-1f1c-4c34-98c4-b89054310ba3-0', usage_metadata={'input_tokens': 17, 'output_tokens': 6, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RunnablePassthrough ëŠ” runnable ê°ì²´ì´ë©°, runnable ê°ì²´ëŠ” invoke() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë³„ë„ ì‹¤í–‰ì´ ê°€ëŠ¥\n",
    "# RunnablePassthrough()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ êµ¬ì„±\n",
    "runnable_chain = {\"word\": RunnablePassthrough()} | prompt | ChatOpenAI()\n",
    "\n",
    "# dict ê°’ì´ RunnablePassthrough() ë¡œ ë³€ê²½ë¨\n",
    "runnable_chain.invoke('ì¸ê³µì§€ëŠ¥')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [ì‹¤ìŠµ] RunnablePassthroughë¥¼ ì‚¬ìš©í•˜ì—¬ ê°’ì„ ë„˜ê²¨ì£¼ëŠ” ì²´ì¸ ì™„ì„±í•˜ê¸°\n",
    "- ì£¼ì œ: íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ ë¬¸êµ¬ ë§Œë“œëŠ” ì±—ë´‡ ë§Œë“¤ê¸°\n",
    "  \n",
    "1. `topic` ë³€ìˆ˜ë¥¼ ë‹´ì€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "2. `marketing_chain` ì„ ë§Œë“¤ì–´ `topic` ë³€ìˆ˜ì— RunnablePassthrough()ë¥¼ ì‚¬ìš©í•œ ì±„ì¸ ë§Œë“¤ê¸°\n",
    "3. `invoke()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ `AI ì±—ë´‡` ë¼ëŠ” ê°’ì„ ë„£ì–´ ì²´ì¸ ì‹¤í–‰í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"ì¸ê³µì§€ëŠ¥ ì±—ë´‡ê³¼ ëŒ€í™”í•˜ë©° ìƒˆë¡œìš´ ì„¸ê³„ë¥¼ ê²½í—˜í•´ë³´ì„¸ìš”! ğŸ¤–ğŸ’¬ #AIì±—ë´‡ #ì¸ê³µì§€ëŠ¥ #ëŒ€í™”íŒŒíŠ¸ë„ˆ #í¸ë¦¬í•œìƒë‹´\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 33, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CJsfp5j2xQWT9kg7Yhe2fsjlyX4kG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d2400fe3-e05a-41cf-bb98-9eadf2de56df-0', usage_metadata={'input_tokens': 33, 'output_tokens': 71, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‹¤ìŠµ ì½”ë“œ \n",
    "prompt = PromptTemplate.from_template(\"{topic} ì£¼ì œì— ëŒ€í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ í™ë³´ ë¬¸êµ¬ ì‘ì„±\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "marketing_chain = {\"topic\": RunnablePassthrough()} | prompt | llm\n",
    "marketing_chain.invoke(\"AI ì±—ë´‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `RunnableParallel`: ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì—(ë³‘ë ¬)ë¡œ ì²˜ë¦¬í•˜ë„ë¡ ë„ì™€ì£¼ëŠ” ë„êµ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain1 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{country} ì˜ ìˆ˜ë„ëŠ”?\")\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "chain2 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{country} ì˜ ë©´ì ì€?\")\n",
    "    | ChatOpenAI()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': AIMessage(content='ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 19, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CJslUjPIztWsf5e0cy2o8J65XU8jB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b23ca6d1-0219-46b1-9f14-12733628dbe1-0', usage_metadata={'input_tokens': 19, 'output_tokens': 10, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'area': AIMessage(content='ëŒ€í•œë¯¼êµ­ì˜ ë©´ì ì€ ì•½ 100,363 kmÂ² ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 20, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CJslUaOT00QtTeRU96xEFb1wuIss1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--768b6553-b3d5-43e6-b6d6-c78b2393dcf1-0', usage_metadata={'input_tokens': 20, 'output_tokens': 22, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_chain = RunnableParallel(capital=chain1, area=chain2)\n",
    "combined_chain.invoke(\"ëŒ€í•œë¯¼êµ­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [ì‹¤ìŠµ] RunnableParallelì„ ì‚¬ìš©í•˜ì—¬ ë‘ ì²´ì¸ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•´ë³´ê¸°\n",
    "- ì£¼ì œ: íŠ¹ì • ë¬¸ì¥ì— ëŒ€í•œ ì¶©ì²­ë„ ì‚¬íˆ¬ë¦¬/ ê²½ìƒë„ ì‚¬íˆ¬ë¦¬ ì±—ë´‡ ë§Œë“¤ê¸°\n",
    "- RunnablePassthrough()ì™€ RunnableParallel() ë™ì‹œì— ì‚¬ìš©í•˜ê¸°\n",
    "- modelì€ `gpt-4o` ëª¨ë¸ ì‚¬ìš©í•˜ê¸°\n",
    "  \n",
    "1. `sentence` ë³€ìˆ˜ì— ì‚¬íˆ¬ë¦¬ë¡œ ë°”ê¾¸ê³  ì‹¶ì€ ë¬¸ì¥ ì…ë ¥ ë°›ê¸°\n",
    "2. chain1: `sentence`ë¥¼ ì¶©ì²­ë„ ì‚¬íˆ¬ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ì²´ì¸ êµ¬ì„±\n",
    "3. chain2: `sentence`ë¥¼ ê²½ìƒë„ ì‚¬íˆ¬ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ì²´ì¸ êµ¬ì„±\n",
    "4. RunnableParallelì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶©ì²­ë„ ì‚¬íˆ¬ë¦¬: content='ì¶©ì²­ë„ ì‚¬íˆ¬ë¦¬ë¡œ ë³€í™˜í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\\n\\n\"ì‚¬íˆ¬ë¦¬ì˜ íŠ¹ì§•ì ì¸ ì–µì–‘ì´ë‚˜ í‘œí˜„ì„ ì¨ì„œ ë¬¸ì¥ì„ ë§Œë“¤ ìˆ˜ ìˆìŠˆ.\"' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 42, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CJsxIUzVceFm7obtyBzROvDCPZDoB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--c2d01a37-0f80-4a02-bd38-e73fc0d7f165-0' usage_metadata={'input_tokens': 42, 'output_tokens': 41, 'total_tokens': 83, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "ê²½ìƒë„ ì‚¬íˆ¬ë¦¬: content='ì‚¬íˆ¬ë¦¬ì˜ íŠ¹ì§•ì ì¸ ì–µì–‘ì´ë‚˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì„ ë§Œë“¤ ìˆ˜ ìˆë°ì´.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 42, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CJsxIkVufhbAkkZpLC1hKMamb0ODj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--23360201-f784-4b3b-9193-19bf82a98a5a-0' usage_metadata={'input_tokens': 42, 'output_tokens': 22, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ìŠµ ì½”ë“œ\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "chain1 = (\n",
    "    {\"sentence\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{sentence} ë¥¼ ì¶©ì²­ë„ ì‚¬íˆ¬ë¦¬ë¡œ ë³€í™˜\")\n",
    "    | model\n",
    ")\n",
    "chain2 = (\n",
    "    {\"sentence\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{sentence} ë¥¼ ê²½ìƒë„ ì‚¬íˆ¬ë¦¬ë¡œ ë³€í™˜\")\n",
    "    | model\n",
    ")\n",
    "\n",
    "# ë³‘ë ¬ ì²´ì¸ ì •ì˜ (í‚¤ì›Œë“œ ë§¤í•‘ ë°©ì‹)\n",
    "combined_chain = RunnableParallel(\n",
    "    chungcheong=chain1,\n",
    "    gyeongsang=chain2\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "sentence = \"ì‚¬íˆ¬ë¦¬ì˜ íŠ¹ì§•ì ì¸ ì–µì–‘ì´ë‚˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "result = combined_chain.invoke({\"sentence\": sentence})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ì¶©ì²­ë„ ì‚¬íˆ¬ë¦¬:\", result[\"chungcheong\"])\n",
    "print(\"ê²½ìƒë„ ì‚¬íˆ¬ë¦¬:\", result[\"gyeongsang\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `RunnableLambda`: ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ ë§¤í•‘í•˜ë„ë¡ ë„ì™€ì£¼ëŠ” ë„êµ¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "def concat_output(text):\n",
    "    return text['capital'].content + ' ' + text['area'].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = (combined_chain\n",
    "            | {'info': RunnableLambda(concat_output)} \n",
    "            | PromptTemplate.from_template(\"{info}ì˜ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ê³ , ì´ëª¨ì§€ë¥¼ ë„£ì–´ì¤˜.\")\n",
    "            | ChatOpenAI())\n",
    "\n",
    "final_chain.invoke(\"ëŒ€í•œë¯¼êµ­\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_today(a):\n",
    "    # ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    return datetime.today().strftime(\"%b-%d\")\n",
    "\n",
    "\n",
    "# ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ì¶œë ¥\n",
    "get_today(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# prompt ì™€ llm ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"{today} ê°€ ìƒì¼ì¸ ëŒ€í•œë¯¼êµ­ ìœ ëª…ì¸ {n} ëª…ì„ ë‚˜ì—´í•˜ì„¸ìš”. ìƒë…„ì›”ì¼ì„ í‘œê¸°í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = (\n",
    "    {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥\n",
    "print(chain.invoke(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
