{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습] LangChain 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습에서는 Lang chain에 대해서 학습합니다. OPEN AI의 API KEY를 기반으로 하여 여러 실습을 진행해보고자 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open AI의  KEY 발급 안내\n",
    "\n",
    "OpenAI의 API는 아래의 링크에서 발급 받을 수 있습니다. \n",
    "\n",
    "- OpenAI API 발급 : https://platform.openai.com/settings/organization/api-keys\n",
    "\n",
    "\n",
    "\n",
    "<b>API를 사용하기 위해서는 ChatGPT의 유료 플랜 구독과는 별도로 유료 토큰을 구매하여 사용해야 합니다.</b>\n",
    "\n",
    "- 본 실습 위해 미리 발급받은 실습용 OpenAI의 API를 제공해드릴 예정입니다.\n",
    "\n",
    "- <b>제한되어 있는 key이기 때문에 본 실습 이외의 용도로 사용될 수 없음을 미리 안내드립니다.</b>\n",
    "\n",
    "\n",
    "실습에서 사용된 함수 이외의 다른 자료는 아래의 [Open AI의 Docs]를 참고해주세요.\n",
    "\n",
    "또한, Open AI API를 활용하여 다양한 프롬프트를 코드에서 활용해볼 수 있습니다.\n",
    "\n",
    "- 참고자료 1 : docs (https://platform.openai.com/docs/models#models-overview)\n",
    "\n",
    "- 참고자료 2 : Prompt examples (https://platform.openai.com/docs/examples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35366,
     "status": "ok",
     "timestamp": 1728127907273,
     "user": {
      "displayName": "송유이",
      "userId": "04571971252639592032"
     },
     "user_tz": -540
    },
    "id": "FvMINDp04WPH",
    "outputId": "8513eb15-0dec-47f1-9f4a-193fad81f731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\python312\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai in c:\\python312\\lib\\site-packages (0.3.33)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\python312\\lib\\site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\python312\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\python312\\lib\\site-packages (from langchain) (0.4.29)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\python312\\lib\\site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python312\\lib\\site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python312\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.104.2 in c:\\python312\\lib\\site-packages (from langchain-openai) (1.108.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\python312\\lib\\site-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python312\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.9.18)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.104.2->langchain-openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Lang chain을 위한 패키지 및 기타 패키지들을 설치합니다\n",
    "!pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI : OpenAI 사의 채팅 전용 LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# GPT를 사용할 수 있는 API KEY 입력\n",
    "api_key = \"sk-gRqhsT2_U1YFOGYerzzIoOu1gpw0JmMnrXQosCx_4IT3BlbkFJRTMSFduGtHsnUrIP0Bsf3gfjjk4ucCPXv4Fw3lxXoA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 5096,
     "status": "ok",
     "timestamp": 1728127943293,
     "user": {
      "displayName": "송유이",
      "userId": "04571971252639592032"
     },
     "user_tz": -540
    },
    "id": "Yqs-jwiW59QR",
    "outputId": "a299a481-08cd-4804-b6b0-6254b91c04bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Subject: Inquiry for Grain Trade\\n\\nDear [Recipient's Name],\\n\\nI hope this message finds you well. My name is [Your Name], and I am [Your Position] at [Your Company Name]. We are a company specializing in [brief description of your company and its activities], and we are currently looking to expand our supply chain for high-quality grains.\\n\\nWe are interested in discussing potential trade opportunities for the following types of grains: [list specific grains you are interested in, e.g., wheat, corn, barley, etc.]. We would like to understand your pricing, availability, and any minimum order quantities you may have.\\n\\nAdditionally, if you could provide us with information regarding your shipping options and lead times, it would be greatly appreciated. We are looking to establish a long-term partnership and would be interested in any bulk purchase discounts you may offer.\\n\\nPlease let us know a convenient time for you to discuss this further. We look forward to your prompt response.\\n\\nThank you for your attention.\\n\\nBest regards,\\n\\n[Your Name]  \\n[Your Position]  \\n[Your Company Name]  \\n[Your Phone Number]  \\n[Your Email Address]  \\n[Your Company Address]  \\n\\n---\\n\\n이 메일을 필요에 맞게 수정하여 사용하시면 됩니다. 추가적인 요청이나 질문이 있으시면 언제든지 말씀해 주세요!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 268, 'prompt_tokens': 28, 'total_tokens': 296, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CHfipWedmIWDFMVDtM84tyV6HQ4Y3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--30f2d3a2-4158-4098-a427-7da398c92964-0', usage_metadata={'input_tokens': 28, 'output_tokens': 268, 'total_tokens': 296, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 객체 생성\n",
    "chat_model = ChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0  # 위에서 선언한 API KEY  # model_name : 적용할 모델명\n",
    ")  # temperature(창의성) : 사용할 샘플링 온도는 0~2 사이에서 선택.\n",
    "# 0.8과 같은 높은 값을 출력을 더 무작위하게 만듦.\n",
    "# 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듦.\n",
    "# max_token(최대 토큰수): 채팅 완성에서 생성할 토큰의 최대 개수\n",
    "\n",
    "# 프롬프트 입력\n",
    "chat_model.invoke(\"영어로 물품 거래(곡물)를 요청하는 비즈니스 메일을 작성해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nJqt9lqZ6Jai"
   },
   "outputs": [],
   "source": [
    "prompt_template = \"당신은 비즈니스 메일 작성 전문가입니다. 협상에 능통하고, 굉장히 예의바른 말투로 메일을 작성할 수 있습니다. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vjM4Lz0ywijV"
   },
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    prompt_template + \"영어로 물품 거래(곡물)를 요청하는 비즈니스 메일을 작성해주세요.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "hxt_Dlk_6y8C",
    "outputId": "a7933300-c4aa-4171-f904-698447934f44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Subject: Inquiry for Grain Supply\\n\\nDear [Recipient's Name],\\n\\nI hope this message finds you well.\\n\\nMy name is [Your Name], and I am [Your Position] at [Your Company Name]. We are currently exploring opportunities to expand our supply chain and are interested in sourcing high-quality grain products.\\n\\nWe would greatly appreciate it if you could provide us with information regarding your available grain varieties, pricing, and any minimum order quantities. Additionally, if you could share your lead times and shipping options, it would be immensely helpful for our planning.\\n\\nWe are committed to establishing a mutually beneficial partnership and are eager to discuss how we can work together effectively. Please let us know a convenient time for you to discuss this further, or feel free to reply to this email with the requested information.\\n\\nThank you for considering our inquiry. I look forward to your prompt response.\\n\\nWarm regards,\\n\\n[Your Name]  \\n[Your Position]  \\n[Your Company Name]  \\n[Your Phone Number]  \\n[Your Email Address]  \", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 203, 'prompt_tokens': 65, 'total_tokens': 268, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CHfiwE4Scjitia9aPmpeeAkRuoIaM', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3af2d1eb-8956-4c5f-99c5-934a59e0bb81-0', usage_metadata={'input_tokens': 65, 'output_tokens': 203, 'total_tokens': 268, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[답변]: 미국의 수도는 워싱턴 D.C.입니다.\n"
     ]
    }
   ],
   "source": [
    "# 질의내용\n",
    "question = \"미국의 수도는 어디니?\"\n",
    "\n",
    "# 질의\n",
    "print(f\"[답변]: {chat_model.invoke(question).content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿 활용\n",
    "PromptTemplate : 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿\n",
    "\n",
    "- template: 템플릿 문자열. 이 문자열 내에서 중괄호 {}는 변수.\n",
    "\n",
    "- input_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 질문 템플릿 형식 정의\n",
    "template = \"{country}의 수도는 뭐야?\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMChain : 특정 PromptTemplate와 연결된 체인 객체를 생성\n",
    "\n",
    "- prompt: 앞서 정의한 PromptTemplate 객체를 사용.\n",
    "\n",
    "- llm: 언어 모델을 나타냄. 위에서 정의한 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glory\\AppData\\Local\\Temp\\ipykernel_13428\\1906816209.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt, llm=chat_model)\n"
     ]
    }
   ],
   "source": [
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glory\\AppData\\Local\\Temp\\ipykernel_13428\\1629882101.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm_chain.run(country=\"일본\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일본의 수도는 도쿄(東京)입니다. 도쿄는 일본의 정치, 경제, 문화의 중심지로, 많은 인구와 다양한 명소가 있는 대도시입니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인을 통해 템플릿 프롬프트 실행\n",
    "print(llm_chain.run(country=\"일본\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'country': '중국', 'text': '중국의 수도는 베이징(北京)입니다.'}, {'country': '프랑스', 'text': '프랑스의 수도는 파리입니다.'}, {'country': '미국', 'text': '미국의 수도는 워싱턴 D.C.입니다.'}]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 입력을 한 번에 실행\n",
    "input_list = [{\"country\": \"중국\"}, {\"country\": \"프랑스\"}, {\"country\": \"미국\"}]\n",
    "\n",
    "print(llm_chain.batch(input_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중국의 수도는 베이징(北京)입니다.\n",
      "프랑스의 수도는 파리입니다.\n",
      "미국의 수도는 워싱턴 D.C.입니다.\n"
     ]
    }
   ],
   "source": [
    "# text 키 값으로 결과가 반환됨 -> 반복문으로 출력\n",
    "\n",
    "# input_list 에 대한 결과 반환\n",
    "result = llm_chain.batch(input_list)\n",
    "\n",
    "# 반복문으로 결과 출력\n",
    "for res in result:\n",
    "    print(res[\"text\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 15, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CHfj6jM7w5JwzjJJiIPvQJLIGy5WU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--872cfd92-0589-4ec2-963a-118fb5a10e53-0', usage_metadata={'input_tokens': 15, 'output_tokens': 13, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))], [ChatGeneration(text='프랑스의 수도는 파리입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='프랑스의 수도는 파리입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 16, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CHfj7cTFsByted0Z6nT8FkSvxx2zE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d093544f-b2ff-45b2-88c1-3842c632dabf-0', usage_metadata={'input_tokens': 16, 'output_tokens': 10, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))], [ChatGeneration(text='미국의 수도는 워싱턴 D.C.입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='미국의 수도는 워싱턴 D.C.입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 15, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CHfj8x3yZJ8Ph9hzrS6TQXg8CyKkH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c379a9ce-9ab7-418d-b91d-924c745c7e5c-0', usage_metadata={'input_tokens': 15, 'output_tokens': 13, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))]] llm_output={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 46, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_560af6e559'} run=[RunInfo(run_id=UUID('872cfd92-0589-4ec2-963a-118fb5a10e53')), RunInfo(run_id=UUID('d093544f-b2ff-45b2-88c1-3842c632dabf')), RunInfo(run_id=UUID('c379a9ce-9ab7-418d-b91d-924c745c7e5c'))] type='LLMResult'\n"
     ]
    }
   ],
   "source": [
    "# LLMResult : 토큰 사용량과 종료 이유와 같은 유용한 생성 정보를 포함함\n",
    "# input_list 에 대한 결과 반환\n",
    "generated_result = llm_chain.generate(input_list)\n",
    "print(generated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 15, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CHfj6jM7w5JwzjJJiIPvQJLIGy5WU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--872cfd92-0589-4ec2-963a-118fb5a10e53-0', usage_metadata={'input_tokens': 15, 'output_tokens': 13, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))],\n",
       " [ChatGeneration(text='프랑스의 수도는 파리입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='프랑스의 수도는 파리입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 16, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CHfj7cTFsByted0Z6nT8FkSvxx2zE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d093544f-b2ff-45b2-88c1-3842c632dabf-0', usage_metadata={'input_tokens': 16, 'output_tokens': 10, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))],\n",
       " [ChatGeneration(text='미국의 수도는 워싱턴 D.C.입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='미국의 수도는 워싱턴 D.C.입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 15, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CHfj8x3yZJ8Ph9hzrS6TQXg8CyKkH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c379a9ce-9ab7-418d-b91d-924c745c7e5c-0', usage_metadata={'input_tokens': 15, 'output_tokens': 13, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 답변 출력\n",
    "generated_result.generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잠깐!! 아래의 형태와 같이 출력해주세요.\n",
    "\n",
    "1 -> 중국의 수도는 베이징(北京)입니다.  \n",
    "2 -> 프랑스의 수도는 파리입니다.  \n",
    "3 -> 미국의 수도는 워싱턴 D.C.입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> 중국의 수도는 베이징(北京)입니다.\n",
      "2 -> 프랑스의 수도는 파리입니다.\n",
      "3 -> 미국의 수도는 워싱턴 D.C.입니다.\n"
     ]
    }
   ],
   "source": [
    "# 여기에 입력하세요!\n",
    "for i, gen in enumerate(generated_result.generations):\n",
    "    print(f\"{i+1} -> {gen[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 36,\n",
       "  'prompt_tokens': 46,\n",
       "  'total_tokens': 82,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-mini',\n",
       " 'system_fingerprint': 'fp_560af6e559'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 사용량 출력\n",
    "generated_result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RunInfo(run_id=UUID('872cfd92-0589-4ec2-963a-118fb5a10e53')),\n",
       " RunInfo(run_id=UUID('d093544f-b2ff-45b2-88c1-3842c632dabf')),\n",
       " RunInfo(run_id=UUID('c379a9ce-9ab7-418d-b91d-924c745c7e5c'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run ID 출력\n",
    "generated_result.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중국의 수도는 베이징(北京)입니다.\n",
      "프랑스의 수도는 파리입니다.\n",
      "미국의 수도는 워싱턴 D.C.입니다.\n"
     ]
    }
   ],
   "source": [
    "# 답변 출력\n",
    "for gen in generated_result.generations:\n",
    "    print(gen[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두 개 이상의 변수를 템플릿 안에 정의 \n",
    "\n",
    "- input_variables를 활용하여 템플릿 구성\n",
    "\n",
    "### 아래의 지역에 대하여, 시차를 구해주세요.\n",
    "\n",
    "1. 파리 - 뉴욕\n",
    "2. 서울 - 도쿄\n",
    "3. 베이징 - 하와이\n",
    "\n",
    "질문 예시 : _\"서울과 파리의 시차는 몇 시간이야?\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국과 일본은 같은 시간대에 속해 있습니다. 따라서 한국과 일본의 시차는 0시간입니다. 두 나라 모두 UTC+9 시간대를 사용하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 질문 템플릿 형식 정의\n",
    "template = \"{area1}와 {area2}의 시차는 몇 시간이야?\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"area1\", \"area2\"])\n",
    "\n",
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=chat_model)\n",
    "\n",
    "# run () : 체인 실행\n",
    "print(llm_chain.run(area1=\"한국\", area2=\"일본\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXdq8ksww07I"
   },
   "source": [
    "## 나만의 프롬프트 엔지니어링을 적용해 질의응답을 받을 수 있는 코드를 만들어주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자유롭게 활용해보세요!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.11.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
